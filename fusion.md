Fusion Methods Explained Simply

  The Problem You're Solving

  You have 4 different "experts" making predictions:
  - Expression expert: 0.65 confidence this patient will respond
  - Methylation expert: 0.72 confidence
  - Protein expert: 0.81 confidence
  - Mutation expert: 0.58 confidence

  Question: How do you combine these into ONE final prediction?

  ---
  Method 1: Weighted Average (Like GPA Calculation)

  Final = (Expert1 Ã— Weight1) + (Expert2 Ã— Weight2) + ...

  Example:
  - Protein is best (AUC 0.74) â†’ gets 30% weight
  - Expression is okay (AUC 0.66) â†’ gets 25% weight
  - Final = (0.81Ã—0.30) + (0.65Ã—0.25) + (0.72Ã—0.25) + (0.58Ã—0.20) = 0.70

  Like: Calculating GPA where important classes count more

  ---
  Method 2: Rank Fusion (Like Sports Rankings)

  Instead of using raw scores, convert to rankings:
  - Patient A: Protein says #5, Expression says #12, Meth says #8, Mutation says #15
  - Average rank: (5+12+8+15)/4 = #10

  Why it's good: Doesn't matter if protein scores 0-100 and expression scores 0-1

  Like: Combining NFL power rankings from different sports writers

  ---
  Method 3: Geometric Mean (Everyone Must Agree)

  Final = âˆœ(Expr Ã— Meth Ã— Protein Ã— Mutation)

  If ANY expert says 0, final is 0. All must be positive.

  Example:
  - 0.8 Ã— 0.7 Ã— 0.9 Ã— 0.6 = 0.74
  - 0.8 Ã— 0.7 Ã— 0.9 Ã— 0.1 = 0.45 (one low score tanks it)

  Like: Restaurant must be good at food AND service AND atmosphere

  ---
  Method 4: ENSEMBLE FUSION (What You Used) ðŸ†

  This is the genius move!

  Instead of picking one method above, Ensemble Fusion:
  1. Tries ALL methods on your training data
  2. Sees which works best
  3. Uses that one for testing

  In your case:
  - Weighted average got 0.747
  - Rank fusion got 0.766 â† WINNER!
  - Geometric mean got 0.719
  - So ensemble picked rank fusion

  ---
  Why Ensemble Fusion Got You 0.771

  Think of it like hiring a team manager who:
  1. Watches how each fusion method performs
  2. Learns that rank fusion works best for YOUR data
  3. Delegates to rank fusion for final predictions

  It's adaptive!
  - If your data had different characteristics, it might pick weighted average
  - It automatically finds what works best

  ---
  Real-World Analogy

  You're predicting if a student will pass a difficult exam using:
  - Homework scores (Expression)
  - Class participation (Methylation)
  - Previous test scores (Protein)
  - Study hours (Mutation)

  Weighted Average: "Test scores count 40%, homework 30%..."
  Rank Fusion: "This student ranks #5 in tests, #12 in homework..."
  Geometric Mean: "Must be good at everything"
  Ensemble: "Let me check which method best predicted last year's class, then use that"

  ---
  The Bottom Line

  Ensemble Fusion = Smart manager that picks the best fusion method for YOUR specific data

  That's why you got 0.771 instead of 0.747 (if you only used weighted) or 0.719 (if you only used geometric)!






'/Users/tobyliu/Pictures/Photos Library.photoslibrary/originals/E/E1A25A6D-4E3E-4EFA-AB96-05519A9F060A.jpeg'                                              â”‚
â”‚   ok heres the deal, I am a current summer undergraduate research intern at Houston Methodist. This entire directory we are in rigth now is the project I   â”‚
â”‚   have been working on the entire internship. at the end of the internship (which is coming up soon) I am supposed to compile all of my findings into a     â”‚
â”‚   research poster. What I want you to do is this:                                                           â”‚
â”‚   1. get familiar with this entire project/folder/directory, everything in it. I want you to first, thoroughly review all the raw datasets:                 â”‚
â”‚   BLCA_expression, BLCA_methylation, BLCA_mutation, BLCA_phenotype, and BLCA_protein_expression. Than, thoroughly review all python scripts in order,       â”‚
â”‚   starting withthe scripts in 01_data_preparation, than 02_model_training, then 03_fusion_approaches. get VERY familiar with the entire pipeline/process    â”‚
â”‚   of us getting from raw data to our top two best model fusion AUC scores of .7712 and .7659(results in advanced_fusion_results folder from step7_fusion_advanced.py    â”‚
â”‚   script), honestly too, for the 03_fusion_approaches folder, JUST focus on the step7_fusion_advanced.py script, because thats the one that yielded our     â”‚
â”‚   best results, and the only one we will really be presenting. once you are familiar with the raw data and the scripts pipeline, review the outputs of the  â”‚
â”‚   scripts to see what our results are, results for fusion are in advanced_fusion_results folder, results for individual modalities are in                   â”‚
â”‚   individual_model_results.json. Review the resutls and understand the process we used    â”‚
â”‚   to get there. The entire goal of this first step is to just thoroughly review what we have done in this project to get us ready to create/brainstorm figures for the research poster. Please use as many tokens and as much time as you need to do this part, it is crucial before we move on, because if you dont understsand our project well, we will not be able to build meaningful eye catching figures for the poster. Once you are done let me know and we can brainstorm what figures to put.

                                                                                                                         â”‚
â”‚   2. Once you have finished with the steps above. start thinking about the important points you want to make on the project, mainly they are going to be    â”‚
â”‚   individual modalities vs fused modalities performance, and I also want to briefly include the expression_comparison_results from                          â”‚
â”‚   compare_expression_vs_embedded.py script which compares the performance of the embedded expression dataset using scFoundation vs our preprocessing        â”‚
â”‚   pipeline. just to show that I messed around with LLMs in biology and our preprocessing outperformed it. My professor already filled out the background    â”‚
â”‚   and objectives/hypotheses section for me:                                                                                                                 â”‚
â”‚   [Pasted text #1 +9 lines]                                                                                                                                 â”‚
â”‚   so all you need to do is fill out the rest, no need to worry about acknowledgements and references, my professor will also fill that out for me. just     â”‚
â”‚   focus on methods, results, figures, and future actions. but thats why you must od step 1 good and thoroughly the first time, so you understand            â”‚
â”‚   everything done in this project enough to write about it in the poster well.                                                                              â”‚
â”‚   3. this next step could be part of the above step, but its generating the figures. I already have a figure generating script called                       â”‚
â”‚   create_poster_figures.py where figure outputs are stored in poster_figures folder, I want you to review the script and the figures produced. I only say   â”‚
â”‚   this because those figures are based on old results and methods, so I want you to make new figures that you think convey the most meaningful              â”‚
â”‚   infformation and findings from this project to the viewers. Keep in mind my poster only has enough space for 6 figures, so make 6 figures, but make them  â”‚
â”‚   MEANINGFUL AND PACKED WITH INFORMATION/FINDINGS.                                                                                                          â”‚
â”‚   4. Next, one of the main points of this model is to compare my results and findings and accuracy of my model (AUC of .7712) to current papers doing       â”‚
â”‚   similar things but achieving lower AUC score using much more complex models, here are three comparable papers below:                                      â”‚
â”‚   '/Users/tobyliu/competitive_paper_three.pdf' '/Users/tobyliu/competitive_paper_two.pdf'                                                                   â”‚
â”‚   '/Users/tobyliu/competitor_paper.pdf'                                                                                                                     â”‚
â”‚   all in the root of this directory as PDF's. you dont need to look through these too thoroughly, just understand the point they are trying to get across   â”‚
â”‚   and their findings and briefly compare our results and howe we beat their resutls using a simpler model on genomic data.                                  â”‚
â”‚   5. Last but not least, I am an undergrad, but my professor told me I am doing PhD level work, so please act as my professor, and fill out this poster     â”‚
â”‚   template as such. Make it seem like a PhD student / full time senior Machine Learning bioinformatics professor wrote this poster and did this project.    â”‚
â”‚   We have very exciting findings that beat current papers, and we want it to be presented as such. FOCUS HEAVY ON FIGURES, figures is what catches the      â”‚
â”‚   viewers and the judges' eyes, so make sure they are meaningful and clear.                                                                                 â”‚
â”‚   I know I just threw a lot at you, but I want it to be good, so please take this process slow. We are in a brand new context window now, and I expect you  â”‚
â”‚   to use the ENTIRE WINDOW, and maybe even spend a couple hours to think thats no problem. I want this end product to be good, so each step matters         â”‚
â”‚   because the next builds on the last, so from the very beginning, do it with heart, really understand the data, the process, and our results, and convey   â”‚
â”‚   it to the viewers in the poster at a PhD level. You are a pro at machine learning and bioinformatics, and you want us to succeeed, ready? :)




Step 4 Preprocessing Summary:
  - Expression: 20,530 â†’ 17,689 features (removed genes with >80% zeros and bottom 5% variance)
  - Methylation: ~495,000 â†’ 39,575 features (removed CpGs with >20% missing, kept top 10% variance)
  - Protein: 245 â†’ 185 features (removed proteins with >25% missing, bottom 5% variance)
  - Mutation: 40,543 â†’ 1,725 features (frequency filtering: 3% general, 1% cancer genes, includes pathway features)


âº Individual Modality Performance Summary:
  - Protein: 0.704 AUC (100 features) - BEST
  - Expression: 0.672 AUC (500 features)
  - Methylation: 0.656 AUC (2000 features)
  - Mutation: 0.621 AUC (1000 features)


âº Complete Understanding of the Pipeline:

  1. Data Journey: 437 â†’ 284 â†’ 227 samples

  - Started with 437 TCGA bladder cancer patients
  - 368 had valid treatment outcomes
  - 284 had data in all modalities
  - Final: 227 training, 57 test samples

  2. Feature Engineering Pipeline:

  - Expression: 20,530 â†’ 17,689 features
    - Removed genes with >80% zeros
    - Removed bottom 5% variance genes
    - Standardized
  - Methylation: ~495,000 â†’ 39,575 CpGs
    - Removed CpGs with >20% missing
    - Kept top 10% variance
    - KNN imputation
  - Protein: 245 â†’ 185 proteins
    - Removed proteins with >25% missing
    - Median imputation
    - Removed bottom 5% variance
  - Mutation: 40,543 â†’ 1,725 features
    - Fisher's exact test filtering
    - 3% frequency threshold (general genes)
    - 1% threshold (known cancer genes)
    - Added pathway features

  3. Model Training Approach:

  - Two-phase adaptive feature selection
    - Phase 1: Broad search across feature counts
    - Phase 2: Refinement around best configs
  - 5 model types: Logistic Regression, Random Forest, XGBoost, ElasticNet, MLP
  - All within CV folds - no data leakage

  4. The Winning Configuration (0.7712 AUC):

  - Strategy: Diverse (high feature counts)
  - Features:
    - Expression: 6000
    - Methylation: 1000
    - Protein: 110
    - Mutation: 1000
  - Fusion Method: Ensemble (automatically selects best from weighted, rank, geometric)
  - 5-fold CV results: [0.864, 0.763, 0.745, 0.776, 0.707]

  5. Key Insights:

  - Protein is the strongest individual modality (0.704)
  - Fusion improves by +0.067 over best individual
  - Minimal strategy (300 expr features) achieves 0.766 - nearly as good!
  - Your preprocessing outperformed scFoundation embeddings (0.653 vs 0.570)

  Now I have a thorough understanding of your entire project. Let me create a comprehensive plan for your poster with meaningful figures based on actual
  data: